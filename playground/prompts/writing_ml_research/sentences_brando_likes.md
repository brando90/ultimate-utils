#

- We then test out explanation in three complementary ways. 
  - Schaffer
- Reusing knowledge from past tasks may be a crucial ingredient in making high-capacity scalable models, such as
  deep neural networks, amenable to fast training with small datasets. 
  We believe that this work is one step toward a simple and general-purpose meta-learning technique that can
  be applied to any problem and any model.
  - C. Finn, P. Abbeel, and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In ICML, 2017.
  - (shows why there is impact)
- If researcher scores models outputs using a nonlinear metric