{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to test impots\n",
    "import sys\n",
    "\n",
    "for path in sys.path:\n",
    "    print(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler('employee.log')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "class Employee:\n",
    "    \"\"\"A sample Employee class\"\"\"\n",
    "\n",
    "    def __init__(self, first, last):\n",
    "        self.first = first\n",
    "        self.last = last\n",
    "\n",
    "        logger.info('Created Employee: {} - {}'.format(self.fullname, self.email))\n",
    "\n",
    "    @property\n",
    "    def email(self):\n",
    "        return '{}.{}@email.com'.format(self.first, self.last)\n",
    "\n",
    "    @property\n",
    "    def fullname(self):\n",
    "        return '{} {}'.format(self.first, self.last)\n",
    "\n",
    "emp_1 = Employee('John', 'Smith')\n",
    "emp_2 = Employee('Corey', 'Schafer')\n",
    "emp_3 = Employee('Jane', 'Doe')\n",
    "\n",
    "######## END OF EMPLOYEE LOGGING EXAMPLE\n",
    "\n",
    "def report_times(start, verbose=False):\n",
    "    '''\n",
    "    How much time has passed since the time \"start\"\n",
    "\n",
    "    :param float start: the number representing start (usually time.time())\n",
    "    '''\n",
    "    meta_str=''\n",
    "    ## REPORT TIMES\n",
    "    start_time = start\n",
    "    seconds = (time.time() - start_time)\n",
    "    minutes = seconds/ 60\n",
    "    hours = minutes/ 60\n",
    "    if verbose:\n",
    "        print(f\"--- {seconds} {'seconds '+meta_str} ---\")\n",
    "        print(f\"--- {minutes} {'minutes '+meta_str} ---\")\n",
    "        print(f\"--- {hours} {'hours '+meta_str} ---\")\n",
    "        print('\\a')\n",
    "    ##\n",
    "    msg = f'time passed: hours:{hours}, minutes={minutes}, seconds={seconds}'\n",
    "    return msg, seconds, minutes, hours\n",
    "\n",
    "def params_in_comp_graph():\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torchviz import make_dot\n",
    "    fc0 = nn.Linear(in_features=3,out_features=1)\n",
    "    params = [('fc0', fc0)]\n",
    "    mdl = nn.Sequential(OrderedDict(params))\n",
    "\n",
    "    x = torch.randn(1,3)\n",
    "    #x.requires_grad = True  # uncomment to put in computation graph\n",
    "    y = torch.randn(1)\n",
    "\n",
    "    l = ( mdl(x) - y )**2\n",
    "\n",
    "    #make_dot(l, params=dict(mdl.named_parameters()))\n",
    "    params = dict(mdl.named_parameters())\n",
    "    #params = {**params, 'x':x}\n",
    "    make_dot(l,params=params).render('data/debug/test_img_l',format='png')\n",
    "\n",
    "def check_if_tensor_is_detached():\n",
    "    a = torch.tensor([2.0], requires_grad=True)\n",
    "    b = a.detach()\n",
    "    b.requires_grad = True\n",
    "    print(a == b)\n",
    "    print(a is b)\n",
    "    print(a)\n",
    "    print(b)\n",
    "\n",
    "    la = (5.0 - a)**2\n",
    "    la.backward()\n",
    "    print(f'a.grad = {a.grad}')\n",
    "\n",
    "    lb = (6.0 - b)**2\n",
    "    lb.backward()\n",
    "    print(f'b.grad = {b.grad}')\n",
    "\n",
    "def deep_copy_issue():\n",
    "    params = OrderedDict( [('fc1',nn.Linear(in_features=3,out_features=1))] )\n",
    "    mdl0 = nn.Sequential(params)\n",
    "    mdl1 = copy.deepcopy(mdl0)\n",
    "    print(id(mdl0))\n",
    "    print(mdl0)\n",
    "    print(id(mdl1))\n",
    "    print(mdl1)\n",
    "    # my update\n",
    "    mdl1.fc1.weight = nn.Parameter( mdl1.fc1.weight + 1 )\n",
    "    mdl2 = copy.deepcopy(mdl1)\n",
    "    print(id(mdl2))\n",
    "    print(mdl2)\n",
    "\n",
    "def download_mini_imagenet():\n",
    "    # download mini-imagenet automatically\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchvision.datasets.utils as utils\n",
    "    from torchvision.datasets.utils import download_and_extract_archive\n",
    "    from torchvision.datasets.utils import download_file_from_google_drive\n",
    "\n",
    "    ## download mini-imagenet\n",
    "    #url = 'https://drive.google.com/file/d/1rV3aj_hgfNTfCakffpPm7Vhpr1in87CR'\n",
    "    file_id = '1rV3aj_hgfNTfCakffpPm7Vhpr1in87CR'\n",
    "    filename = 'miniImagenet.tgz'\n",
    "    root = '~/tmp/' # dir to place downloaded file in\n",
    "    download_file_from_google_drive(file_id, root, filename)\n",
    "\n",
    "def extract():\n",
    "    from torchvision.datasets.utils import extract_archive\n",
    "    from_path = os.path.expanduser('~/Downloads/miniImagenet.tgz')\n",
    "    extract_archive(from_path)\n",
    "\n",
    "def download_and_extract_miniImagenet(root):\n",
    "    import os\n",
    "    from torchvision.datasets.utils import download_file_from_google_drive, extract_archive\n",
    "\n",
    "    ## download miniImagenet\n",
    "    #url = 'https://drive.google.com/file/d/1rV3aj_hgfNTfCakffpPm7Vhpr1in87CR'\n",
    "    file_id = '1rV3aj_hgfNTfCakffpPm7Vhpr1in87CR'\n",
    "    filename = 'miniImagenet.tgz'\n",
    "    download_file_from_google_drive(file_id, root, filename)\n",
    "    fpath = os.path.join(root, filename) # this is what download_file_from_google_drive does\n",
    "    ## extract downloaded dataset\n",
    "    from_path = os.path.expanduser(fpath)\n",
    "    extract_archive(from_path)\n",
    "    ## remove the zip file\n",
    "    os.remove(from_path)\n",
    "\n",
    "def torch_concat():\n",
    "    import torch\n",
    "\n",
    "    g1 = torch.randn(3,3)\n",
    "    g2 = torch.randn(3,3)\n",
    "\n",
    "def inner_loop1():\n",
    "    n_inner_iter = 5\n",
    "    inner_opt = torch.optim.SGD(net.parameters(), lr=1e-1)\n",
    "\n",
    "    qry_losses = []\n",
    "    qry_accs = []\n",
    "    meta_opt.zero_grad()\n",
    "    for i in range(task_num):\n",
    "        with higher.innerloop_ctx(\n",
    "            net, inner_opt, copy_initial_weights=False\n",
    "        ) as (fnet, diffopt):\n",
    "            # Optimize the likelihood of the support set by taking\n",
    "            # gradient steps w.r.t. the model's parameters.\n",
    "            # This adapts the model's meta-parameters to the task.\n",
    "            # higher is able to automatically keep copies of\n",
    "            # your network's parameters as they are being updated.\n",
    "            for _ in range(n_inner_iter):\n",
    "                spt_logits = fnet(x_spt[i])\n",
    "                spt_loss = F.cross_entropy(spt_logits, y_spt[i])\n",
    "                diffopt.step(spt_loss)\n",
    "\n",
    "            # The final set of adapted parameters will induce some\n",
    "            # final loss and accuracy on the query dataset.\n",
    "            # These will be used to update the model's meta-parameters.\n",
    "            qry_logits = fnet(x_qry[i])\n",
    "            qry_loss = F.cross_entropy(qry_logits, y_qry[i])\n",
    "            qry_losses.append(qry_loss.detach())\n",
    "            qry_acc = (qry_logits.argmax(\n",
    "                dim=1) == y_qry[i]).sum().item() / querysz\n",
    "            qry_accs.append(qry_acc)\n",
    "\n",
    "            # Update the model's meta-parameters to optimize the query\n",
    "            # losses across all of the tasks sampled in this batch.\n",
    "            # This unrolls through the gradient steps.\n",
    "            qry_loss.backward()\n",
    "\n",
    "    meta_opt.step()\n",
    "    qry_losses = sum(qry_losses) / task_num\n",
    "    qry_accs = 100. * sum(qry_accs) / task_num\n",
    "    i = epoch + float(batch_idx) / n_train_iter\n",
    "    iter_time = time.time() - start_time\n",
    "\n",
    "def inner_loop2():\n",
    "    n_inner_iter = 5\n",
    "    inner_opt = torch.optim.SGD(net.parameters(), lr=1e-1)\n",
    "\n",
    "    qry_losses = []\n",
    "    qry_accs = []\n",
    "    meta_opt.zero_grad()\n",
    "    meta_loss = 0\n",
    "    for i in range(task_num):\n",
    "        with higher.innerloop_ctx(\n",
    "            net, inner_opt, copy_initial_weights=False\n",
    "        ) as (fnet, diffopt):\n",
    "            # Optimize the likelihood of the support set by taking\n",
    "            # gradient steps w.r.t. the model's parameters.\n",
    "            # This adapts the model's meta-parameters to the task.\n",
    "            # higher is able to automatically keep copies of\n",
    "            # your network's parameters as they are being updated.\n",
    "            for _ in range(n_inner_iter):\n",
    "                spt_logits = fnet(x_spt[i])\n",
    "                spt_loss = F.cross_entropy(spt_logits, y_spt[i])\n",
    "                diffopt.step(spt_loss)\n",
    "\n",
    "            # The final set of adapted parameters will induce some\n",
    "            # final loss and accuracy on the query dataset.\n",
    "            # These will be used to update the model's meta-parameters.\n",
    "            qry_logits = fnet(x_qry[i])\n",
    "            qry_loss = F.cross_entropy(qry_logits, y_qry[i])\n",
    "            qry_losses.append(qry_loss.detach())\n",
    "            qry_acc = (qry_logits.argmax(\n",
    "                dim=1) == y_qry[i]).sum().item() / querysz\n",
    "            qry_accs.append(qry_acc)\n",
    "\n",
    "            # Update the model's meta-parameters to optimize the query\n",
    "            # losses across all of the tasks sampled in this batch.\n",
    "            # This unrolls through the gradient steps.\n",
    "            #qry_loss.backward()\n",
    "            meta_loss += qry_loss\n",
    "\n",
    "    qry_losses = sum(qry_losses) / task_num\n",
    "    qry_losses.backward()\n",
    "    meta_opt.step()\n",
    "    qry_accs = 100. * sum(qry_accs) / task_num\n",
    "    i = epoch + float(batch_idx) / n_train_iter\n",
    "    iter_time = time.time() - start_time\n",
    "\n",
    "def error_unexpected_way_to_by_pass_safety():\n",
    "    # https://stackoverflow.com/questions/62415251/why-am-i-able-to-change-the-value-of-a-tensor-without-the-computation-graph-know\n",
    "\n",
    "    import torch\n",
    "    a = torch.tensor([1,2,3.], requires_grad=True)\n",
    "    # are detached tensor's leafs? yes they are\n",
    "    a_detached = a.detach()\n",
    "    #a.fill_(2) # illegal, warns you that a tensor which requires grads is used in an inplace op (so it won't be recorded in computation graph so it wont take the right derivative of the forward path as this op won't be in it)\n",
    "    a_detached.fill_(2) # weird that this one is allowed, seems to allow me to bypass the error check from the previous comment...?!\n",
    "    print(f'a = {a}')\n",
    "    print(f'a_detached = {a_detached}')\n",
    "    a.sum().backward()\n",
    "\n",
    "def detach_playground():\n",
    "    import torch\n",
    "\n",
    "    a = torch.tensor([1,2,3.], requires_grad=True)\n",
    "    # are detached tensor's leafs? yes they are\n",
    "    a_detached = a.detach()\n",
    "    print(f'a_detached.is_leaf = {a_detached.is_leaf}')\n",
    "    # is doing sum on the detached tensor a leaf? no\n",
    "    a_detached_sum = a.sum()\n",
    "    print(f'a_detached_sum.is_leaf = {a_detached_sum.is_leaf}')\n",
    "    # is detaching an intermediate tensor a leaf? yes\n",
    "    a_sum_detached = a.sum().detach()\n",
    "    print(f'a_sum_detached.is_leaf = {a_sum_detached.is_leaf}')\n",
    "    # shows they share they same data\n",
    "    print(f'a == a_detached = {a == a_detached}')\n",
    "    print(f'a is a_detached = {a is a_detached}')\n",
    "    a_detached.zero_()\n",
    "    print(f'a = {a}')\n",
    "    print(f'a_detached = {a_detached}')\n",
    "    #a.fill_(2) # illegal, warns you that a tensor which requires grads is used in an inplace op (so it won't be recorded in computation graph so it wont take the right derivative of the forward path as this op won't be in it)\n",
    "    a_detached.fill_(2) # weird that this one is allowed, seems to allow me to bypass the error check from the previous comment...?!\n",
    "    print(f'a = {a}')\n",
    "    print(f'a_detached = {a_detached}')\n",
    "    ## conclusion: detach basically creates a totally new tensor which cuts gradient computations to the original but shares the same memory with original\n",
    "    out = a.sigmoid()\n",
    "    out_detached = out.detach()\n",
    "    out_detached.zero_()\n",
    "    out.sum().backward()\n",
    "\n",
    "def clone_playground():\n",
    "    import torch\n",
    "\n",
    "    a = torch.tensor([1,2,3.], requires_grad=True)\n",
    "    a_clone = a.clone()\n",
    "    print(f'a_clone.is_leaf = {a_clone.is_leaf}')\n",
    "    print(f'a is a_clone = {a is a_clone}')\n",
    "    print(f'a == a_clone = {a == a_clone}')\n",
    "    print(f'a = {a}')\n",
    "    print(f'a_clone = {a_clone}')\n",
    "    #a_clone.fill_(2)\n",
    "    a_clone.mul_(2)\n",
    "    print(f'a = {a}')\n",
    "    print(f'a_clone = {a_clone}')\n",
    "    a_clone.sum().backward()\n",
    "    print(f'a.grad = {a.grad}')\n",
    "\n",
    "def clone_vs_deepcopy():\n",
    "    import copy\n",
    "    import torch\n",
    "\n",
    "    x = torch.tensor([1,2,3.])\n",
    "    x_clone = x.clone()\n",
    "    x_deep_copy = copy.deepcopy(x)\n",
    "    #\n",
    "    x.mul_(-1)\n",
    "    print(f'x = {x}')\n",
    "    print(f'x_clone = {x_clone}')\n",
    "    print(f'x_deep_copy = {x_deep_copy}')\n",
    "    print()\n",
    "\n",
    "def inplace_playground():\n",
    "    import torch\n",
    "\n",
    "    x = torch.tensor([1,2,3.], requires_grad=True)\n",
    "    y = x + 1\n",
    "    print(f'x.is_leaf = {x.is_leaf}')\n",
    "    print(f'y.is_leaf = {y.is_leaf}')\n",
    "    x += 1 # not allowed because x is a leaf, since changing the value of a leaf with an inplace forgets it's value then backward wouldn't work IMO (though its not the official response)\n",
    "    print(f'x.is_leaf = {x.is_leaf}')\n",
    "\n",
    "def copy_initial_weights_playground_original():\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import higher\n",
    "    import numpy as np\n",
    "\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(3)\n",
    "    N = 100\n",
    "    actual_multiplier = 3.5\n",
    "    meta_lr = 0.00001\n",
    "    loops = 5 # how many iterations in the inner loop we want to do\n",
    "\n",
    "    x = torch.tensor(np.random.random((N,1)), dtype=torch.float64) # features for inner training loop\n",
    "    y = x * actual_multiplier # target for inner training loop\n",
    "    model = nn.Linear(1, 1, bias=False).double() # simplest possible model - multiple input x by weight w without bias\n",
    "    meta_opt = optim.SGD(model.parameters(), lr=meta_lr, momentum=0.)\n",
    "\n",
    "\n",
    "    def run_inner_loop_once(model, verbose, copy_initial_weights):\n",
    "        lr_tensor = torch.tensor([0.3], requires_grad=True)\n",
    "        momentum_tensor = torch.tensor([0.5], requires_grad=True)\n",
    "        opt = optim.SGD(model.parameters(), lr=0.3, momentum=0.5)\n",
    "        with higher.innerloop_ctx(model, opt, copy_initial_weights=copy_initial_weights, override={'lr': lr_tensor, 'momentum': momentum_tensor}) as (fmodel, diffopt):\n",
    "            for j in range(loops):\n",
    "                if verbose:\n",
    "                    print('Starting inner loop step j=={0}'.format(j))\n",
    "                    print('    Representation of fmodel.parameters(time={0}): {1}'.format(j, str(list(fmodel.parameters(time=j)))))\n",
    "                    print('    Notice that fmodel.parameters() is same as fmodel.parameters(time={0}): {1}'.format(j, (list(fmodel.parameters())[0] is list(fmodel.parameters(time=j))[0])))\n",
    "                out = fmodel(x)\n",
    "                if verbose:\n",
    "                    print('    Notice how `out` is `x` multiplied by the latest version of weight: {0:.4} * {1:.4} == {2:.4}'.format(x[0,0].item(), list(fmodel.parameters())[0].item(), out[0].item()))\n",
    "                loss = ((out - y)**2).mean()\n",
    "                diffopt.step(loss)\n",
    "\n",
    "            if verbose:\n",
    "                # after all inner training let's see all steps' parameter tensors\n",
    "                print()\n",
    "                print(\"Let's print all intermediate parameters versions after inner loop is done:\")\n",
    "                for j in range(loops+1):\n",
    "                    print('    For j=={0} parameter is: {1}'.format(j, str(list(fmodel.parameters(time=j)))))\n",
    "                print()\n",
    "\n",
    "            # let's imagine now that our meta-learning optimization is trying to check how far we got in the end from the actual_multiplier\n",
    "            weight_learned_after_full_inner_loop = list(fmodel.parameters())[0]\n",
    "            meta_loss = (weight_learned_after_full_inner_loop - actual_multiplier)**2\n",
    "            print('  Final meta-loss: {0}'.format(meta_loss.item()))\n",
    "            meta_loss.backward() # will only propagate gradient to original model parameter's `grad` if copy_initial_weight=False\n",
    "            if verbose:\n",
    "                print('  Gradient of final loss we got for lr and momentum: {0} and {1}'.format(lr_tensor.grad, momentum_tensor.grad))\n",
    "                print('  If you change number of iterations \"loops\" to much larger number final loss will be stable and the values above will be smaller')\n",
    "            return meta_loss.item()\n",
    "\n",
    "    print('=================== Run Inner Loop First Time (copy_initial_weights=True) =================\\n')\n",
    "    meta_loss_val1 = run_inner_loop_once(model, verbose=True, copy_initial_weights=True)\n",
    "    print(\"\\nLet's see if we got any gradient for initial model parameters: {0}\\n\".format(list(model.parameters())[0].grad))\n",
    "\n",
    "    print('=================== Run Inner Loop Second Time (copy_initial_weights=False) =================\\n')\n",
    "    meta_loss_val2 = run_inner_loop_once(model, verbose=False, copy_initial_weights=False)\n",
    "    print(\"\\nLet's see if we got any gradient for initial model parameters: {0}\\n\".format(list(model.parameters())[0].grad))\n",
    "\n",
    "    print('=================== Run Inner Loop Third Time (copy_initial_weights=False) =================\\n')\n",
    "    final_meta_gradient = list(model.parameters())[0].grad.item()\n",
    "    # Now let's double-check `higher` library is actually doing what it promised to do, not just giving us\n",
    "    # a bunch of hand-wavy statements and difficult to read code.\n",
    "    # We will do a simple SGD step using meta_opt changing initial weight for the training and see how meta loss changed\n",
    "    meta_opt.step()\n",
    "    meta_opt.zero_grad()\n",
    "    meta_step = - meta_lr * final_meta_gradient # how much meta_opt actually shifted inital weight value\n",
    "    meta_loss_val3 = run_inner_loop_once(model, verbose=False, copy_initial_weights=False)\n",
    "\n",
    "def copy_initial_weights_playground():\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import higher\n",
    "    import numpy as np\n",
    "\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(3)\n",
    "    N = 100\n",
    "    actual_multiplier = 3.5 # the parameters we want the model to learn\n",
    "    meta_lr = 0.00001\n",
    "    loops = 5 # how many iterations in the inner loop we want to do\n",
    "\n",
    "    x = torch.randn(N,1) # features for inner training loop\n",
    "    y = x * actual_multiplier # target for inner training loop\n",
    "    model = nn.Linear(1, 1, bias=False)# model(x) = w*x, simplest possible model - multiple input x by weight w without bias. goal is to w~~actualy_multiplier\n",
    "    outer_opt = optim.SGD(model.parameters(), lr=meta_lr, momentum=0.)\n",
    "\n",
    "    def run_inner_loop_once(model, verbose, copy_initial_weights):\n",
    "        lr_tensor = torch.tensor([0.3], requires_grad=True)\n",
    "        momentum_tensor = torch.tensor([0.5], requires_grad=True)\n",
    "        inner_opt = optim.SGD(model.parameters(), lr=0.3, momentum=0.5)\n",
    "        with higher.innerloop_ctx(model, inner_opt, copy_initial_weights=copy_initial_weights, override={'lr': lr_tensor, 'momentum': momentum_tensor}) as (fmodel, diffopt):\n",
    "            for j in range(loops):\n",
    "                if verbose:\n",
    "                    print('Starting inner loop step j=={0}'.format(j))\n",
    "                    print('    Representation of fmodel.parameters(time={0}): {1}'.format(j, str(list(fmodel.parameters(time=j)))))\n",
    "                    print('    Notice that fmodel.parameters() is same as fmodel.parameters(time={0}): {1}'.format(j, (list(fmodel.parameters())[0] is list(fmodel.parameters(time=j))[0])))\n",
    "                out = fmodel(x)\n",
    "                if verbose:\n",
    "                    print(f'    Notice how `out` is `x` multiplied by the latest version of weight: {x[0,0].item()} * {list(fmodel.parameters())[0].item()} == {out[0].item()}')\n",
    "                loss = ((out - y)**2).mean()\n",
    "                diffopt.step(loss)\n",
    "\n",
    "            if verbose:\n",
    "                # after all inner training let's see all steps' parameter tensors\n",
    "                print()\n",
    "                print(\"Let's print all intermediate parameters versions after inner loop is done:\")\n",
    "                for j in range(loops+1):\n",
    "                    print('    For j=={0} parameter is: {1}'.format(j, str(list(fmodel.parameters(time=j)))))\n",
    "                print()\n",
    "\n",
    "            # let's imagine now that our meta-learning optimization is trying to check how far we got in the end from the actual_multiplier\n",
    "            weight_learned_after_full_inner_loop = list(fmodel.parameters())[0]\n",
    "            meta_loss = (weight_learned_after_full_inner_loop - actual_multiplier)**2\n",
    "            print('  Final meta-loss: {0}'.format(meta_loss.item()))\n",
    "            meta_loss.backward() # will only propagate gradient to original model parameter's `grad` if copy_initial_weight=False\n",
    "            if verbose:\n",
    "                print('  Gradient of final loss we got for lr and momentum: {0} and {1}'.format(lr_tensor.grad, momentum_tensor.grad))\n",
    "                print('  If you change number of iterations \"loops\" to much larger number final loss will be stable and the values above will be smaller')\n",
    "            return meta_loss.item()\n",
    "\n",
    "    print('=================== Run Inner Loop First Time (copy_initial_weights=True) =================\\n')\n",
    "    meta_loss_val1 = run_inner_loop_once(model, verbose=True, copy_initial_weights=True)\n",
    "    print(\"\\nLet's see if we got any gradient for initial model parameters: {0}\\n\".format(list(model.parameters())[0].grad))\n",
    "\n",
    "    print('=================== Run Inner Loop Second Time (copy_initial_weights=False) =================\\n')\n",
    "    meta_loss_val2 = run_inner_loop_once(model, verbose=False, copy_initial_weights=False)\n",
    "    print(\"\\nLet's see if we got any gradient for initial model parameters: {0}\\n\".format(list(model.parameters())[0].grad))\n",
    "\n",
    "    print('=================== Run Inner Loop Third Time (copy_initial_weights=False) =================\\n')\n",
    "    final_meta_gradient = list(model.parameters())[0].grad.item()\n",
    "    # Now let's double-check `higher` library is actually doing what it promised to do, not just giving us\n",
    "    # a bunch of hand-wavy statements and difficult to read code.\n",
    "    # We will do a simple SGD step using meta_opt changing initial weight for the training and see how meta loss changed\n",
    "    outer_opt.step()\n",
    "    outer_opt.zero_grad()\n",
    "    meta_step = - meta_lr * final_meta_gradient # how much meta_opt actually shifted inital weight value\n",
    "    meta_loss_val3 = run_inner_loop_once(model, verbose=False, copy_initial_weights=False)\n",
    "\n",
    "    meta_loss_gradient_approximation = (meta_loss_val3 - meta_loss_val2) / meta_step\n",
    "\n",
    "    print()\n",
    "    print('Side-by-side meta_loss_gradient_approximation and gradient computed by `higher` lib: {0:.4} VS {1:.4}'.format(meta_loss_gradient_approximation, final_meta_gradient))\n",
    "\n",
    "def tqdm_torchmeta():\n",
    "    from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "    import torchmeta\n",
    "    from torchmeta.datasets.helpers import miniimagenet\n",
    "\n",
    "    from pathlib import Path\n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ## get args\n",
    "    args = SimpleNamespace(episodes=5,n_classes=5,k_shot=5,k_eval=15,meta_batch_size=1,n_workers=4)\n",
    "    args.data_root = Path(\"~/automl-meta-learning/data/miniImagenet\").expanduser()\n",
    "\n",
    "    ## get meta-batch loader\n",
    "    train_transform = Compose([Resize(84), ToTensor()])\n",
    "    dataset = miniimagenet(\n",
    "        args.data_root,\n",
    "        ways=args.n_classes,\n",
    "        shots=args.k_shot,\n",
    "        test_shots=args.k_eval,\n",
    "        meta_split='train',\n",
    "        download=False)\n",
    "    dataloader = torchmeta.utils.data.BatchMetaDataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.meta_batch_size,\n",
    "        num_workers=args.n_workers)\n",
    "\n",
    "    with tqdm(dataset):\n",
    "        print(f'len(dataloader)= {len(dataloader)}')\n",
    "        for episode, batch in enumerate(dataloader):\n",
    "            print(f'episode = {episode}')\n",
    "            train_inputs, train_labels = batch[\"train\"]\n",
    "            print(f'train_labels[0] = {train_labels[0]}')\n",
    "            print(f'train_inputs.size() = {train_inputs.size()}')\n",
    "            pass\n",
    "            if episode >= args.episodes:\n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    print('pytorch playground!')\n",
    "    # params_in_comp_graph()\n",
    "    #check_if_tensor_is_detached()\n",
    "    #deep_copy_issue()\n",
    "    #download_mini_imagenet()\n",
    "    #extract()\n",
    "    #download_and_extract_miniImagenet(root='~/tmp')\n",
    "    #download_and_extract_miniImagenet(root='~/automl-meta-learning/data')\n",
    "    #torch_concat()\n",
    "    #detach_vs_cloe()\n",
    "    #error_unexpected_way_to_by_pass_safety()\n",
    "    #clone_playground()\n",
    "    #inplace_playground()\n",
    "    #clone_vs_deepcopy()\n",
    "    #copy_initial_weights_playground()\n",
    "    tqdm_torchmeta()\n",
    "    print('--> DONE')\n",
    "    time_passed_msg, _, _, _ = report_times(start)\n",
    "    print(f'--> {time_passed_msg}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version) ##\n",
    "print(sys.path)\n",
    "\n",
    "def helloworld():\n",
    "    print('helloworld')\n",
    "    print('hello12345')\n",
    "\n",
    "def union_dicts():\n",
    "    d1 = {'x':1}\n",
    "    d2 = {'y':2, 'z':3}\n",
    "    d_union = {**d1, **d2}\n",
    "    print(d_union)\n",
    "\n",
    "def get_stdout_old():\n",
    "    import sys\n",
    "\n",
    "    # contents = \"\"\n",
    "    # #with open('some_file.txt') as f:\n",
    "    # #with open(sys.stdout,'r') as f:\n",
    "    # # sys.stdout.mode = 'r'\n",
    "    # for line in sys.stdout.readlines():\n",
    "    #     contents += line\n",
    "    # print(contents)\n",
    "\n",
    "    # print(sys.stdout)\n",
    "    # with open(sys.stdout.buffer) as f:\n",
    "    #     print(f.readline())\n",
    "\n",
    "    # import subprocess\n",
    "\n",
    "    # p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    # stdout = []\n",
    "    # while True:\n",
    "    #     line = p.stdout.readline()\n",
    "    #     stdout.append(line)\n",
    "    #     print( line )\n",
    "    #     if line == '' and p.poll() != None:\n",
    "    #         break\n",
    "    # print( ''.join(stdout) )\n",
    "\n",
    "    import sys\n",
    "    myfile = \"input.txt\"\n",
    "    def print(*args):\n",
    "        __builtins__.print(*args, file=sys.__stdout__)\n",
    "        with open(myfile, \"a+\") as f:\n",
    "            __builtins__.print(*args, file=f)\n",
    "\n",
    "    print('a')\n",
    "    print('b')\n",
    "    print('c')\n",
    "\n",
    "    repr(sys.stdout)\n",
    "\n",
    "\n",
    "def get_stdout():\n",
    "    import sys\n",
    "    myfile = \"my_stdout.txt\"\n",
    "    # redefine print\n",
    "    def print(*args):\n",
    "        __builtins__.print(*args, file=sys.__stdout__)    #prints to terminal\n",
    "        with open(myfile, \"a+\") as f:\n",
    "            __builtins__.print(*args, file=f)    #saves in a file\n",
    "\n",
    "    print('a')\n",
    "    print('b')\n",
    "    print('c')\n",
    "\n",
    "def logging_basic():\n",
    "    import logging\n",
    "    logging.warning('Watch out!')  # will print a message to the console\n",
    "    logging.info('I told you so')  # will not print anything\n",
    "\n",
    "def logging_to_file():\n",
    "    import logging\n",
    "    logging.basicConfig(filename='example.log',level=logging.DEBUG)\n",
    "    #logging.\n",
    "    logging.debug('This message should go to the log file')\n",
    "    logging.info('So should this')\n",
    "    logging.warning('And this, too')\n",
    "\n",
    "def logging_to_file_INFO_LEVEL():\n",
    "    import logging\n",
    "    import sys\n",
    "    format = '{asctime}:{levelname}:{name}:lineno {lineno}:{message}'\n",
    "    logging.basicConfig(filename='example.log',level=logging.INFO,format=format,style='{')\n",
    "    #logging.basicConfig(stream=sys.stdout,level=logging.INFO,format=format,style='{')\n",
    "    #logging.\n",
    "    logging.debug('This message should NOT go to the log file')\n",
    "    logging.info('This message should go to log file')\n",
    "    logging.warning('This, too')\n",
    "\n",
    "def logger_SO_print_and_write_to_my_stdout():\n",
    "    \"\"\"My sample logger code to print to screen and write to file (the same thing).\n",
    "\n",
    "    Note: trying to replace this old answer of mine using a logger:\n",
    "    - https://github.com/CoreyMSchafer/code_snippets/tree/master/Logging-Advanced\n",
    "\n",
    "    Credit:\n",
    "    - https://www.youtube.com/watch?v=jxmzY9soFXg&t=468s\n",
    "    - https://github.com/CoreyMSchafer/code_snippets/tree/master/Logging-Advanced\n",
    "    - https://stackoverflow.com/questions/21494468/about-notset-in-python-logging/21494716#21494716\n",
    "\n",
    "    Other resources:\n",
    "    - https://docs.python-guide.org/writing/logging/\n",
    "    - https://docs.python.org/3/howto/logging.html#logging-basic-tutorial\n",
    "    - https://stackoverflow.com/questions/61084916/how-does-one-make-an-already-opened-file-readable-e-g-sys-stdout/61255375#61255375\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    import logging\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "\n",
    "    ## create directory (& its parents) if it does not exist otherwise do nothing :)\n",
    "    # get current time\n",
    "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    logs_dirpath = Path(f'~/logs/python_playground_logs_{current_time}/').expanduser()\n",
    "    logs_dirpath.mkdir(parents=True, exist_ok=True)\n",
    "    my_stdout_filename = logs_dirpath / Path('my_stdout.log')\n",
    "    # remove my_stdout if it exists (note you can also just create a new log dir/file each time or append to the end of the log file your using)\n",
    "    #os.remove(my_stdout_filename) if os.path.isfile(my_stdout_filename) else None\n",
    "\n",
    "    ## create top logger\n",
    "    logger = logging.getLogger(__name__) # loggers are created in hierarchy using dot notation, thus __name__ ensures no name collisions.\n",
    "    logger.setLevel(logging.DEBUG) # note: use logging.DEBUG, CAREFUL with logging.UNSET: https://stackoverflow.com/questions/21494468/about-notset-in-python-logging/21494716#21494716\n",
    "\n",
    "    ## log to my_stdout.log file\n",
    "    file_handler = logging.FileHandler(filename=my_stdout_filename)\n",
    "    #file_handler.setLevel(logging.INFO) # not setting it means it inherits the logger. It will log everything from DEBUG upwards in severity to this handler.\n",
    "    log_format = \"{asctime}:{levelname}:{lineno}:{name}:{message}\" # see for logrecord attributes https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "    formatter = logging.Formatter(fmt=log_format, style='{') # set the logging format at for this handler\n",
    "    file_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "    ## log to stdout/screen\n",
    "    stdout_stream_handler = logging.StreamHandler(stream=sys.stdout) # default stderr, though not sure the advatages of logging to one or the other\n",
    "    #stdout_stream_handler.setLevel(logging.INFO) # Note: having different set levels means that we can route using a threshold what gets logged to this handler\n",
    "    log_format = \"{name}:{levelname}:-> {message}\" # see for logrecord attributes https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "    formatter = logging.Formatter(fmt=log_format, style='{') # set the logging format at for this handler\n",
    "    stdout_stream_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "    logger.addHandler(hdlr=file_handler) # add this file handler to top logger\n",
    "    logger.addHandler(hdlr=stdout_stream_handler) # add this file handler to top logger\n",
    "\n",
    "    logger.log(logging.NOTSET, 'notset')\n",
    "    logger.debug('debug')\n",
    "    logger.info('info')\n",
    "    logger.warning('warning')\n",
    "    logger.error('error')\n",
    "    logger.critical('critical')\n",
    "\n",
    "def logging_unset_level():\n",
    "    \"\"\"My sample logger explaining UNSET level\n",
    "\n",
    "    Resources:\n",
    "    - https://stackoverflow.com/questions/21494468/about-notset-in-python-logging\n",
    "    - https://www.youtube.com/watch?v=jxmzY9soFXg&t=468s\n",
    "    - https://github.com/CoreyMSchafer/code_snippets/tree/master/Logging-Advanced\n",
    "    \"\"\"\n",
    "    import logging\n",
    "\n",
    "    logger = logging.getLogger(__name__) # loggers are created in hierarchy using dot notation, thus __name__ ensures no name collisions.\n",
    "    print(f'DEFAULT VALUE: logger.level = {logger.level}')\n",
    "\n",
    "    file_handler = logging.FileHandler(filename='my_log.log')\n",
    "    log_format = \"{asctime}:{levelname}:{lineno}:{name}:{message}\" # see for logrecord attributes https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "    formatter = logging.Formatter(fmt=log_format, style='{')\n",
    "    file_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "    stdout_stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    stdout_stream_handler.setLevel(logging.INFO)\n",
    "    log_format = \"{name}:{levelname}:-> {message}\" # see for logrecord attributes https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "    formatter = logging.Formatter(fmt=log_format, style='{')\n",
    "    stdout_stream_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "    logger.addHandler(hdlr=file_handler)\n",
    "    logger.addHandler(hdlr=stdout_stream_handler)\n",
    "\n",
    "    logger.log(logging.NOTSET, 'notset')\n",
    "    logger.debug('debug')\n",
    "    logger.info('info')\n",
    "    logger.warning('warning')\n",
    "    logger.error('error')\n",
    "    logger.critical('critical')\n",
    "\n",
    "def logger():\n",
    "    from pathlib import Path\n",
    "    import logging\n",
    "\n",
    "    # create directory (& its parents) if it does not exist otherwise do nothing :)\n",
    "    logs_dirpath = Path('~/automl-meta-learning/logs/python_playground_logs/').expanduser()\n",
    "    logs_dirpath.mkdir(parents=True, exist_ok=True)\n",
    "    my_stdout_filename = logs_dirpath / Path('my_stdout.log')\n",
    "    # remove my_stdout if it exists (used to have this but now I decided to create a new log & file each)\n",
    "    #os.remove(my_stdout_filename) if os.path.isfile(my_stdout_filename) else None\n",
    "\n",
    "    logger = logging.getLogger(__name__) # loggers are created in hierarchy using dot notation, thus __name__ ensures no name collisions.\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    log_format = \"{asctime}:{levelname}:{name}:{message}\"\n",
    "    formatter = logging.Formatter(fmt=log_format, style='{')\n",
    "\n",
    "    file_handler = logging.FileHandler(filename=my_stdout_filename)\n",
    "    file_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "    logger.addHandler(hdlr=file_handler)\n",
    "    logger.addHandler(hdlr=logging.StreamHandler())\n",
    "\n",
    "    for i in range(3):\n",
    "        logger.info(f'i = {i}')\n",
    "\n",
    "    logger.info(f'logger DONE')\n",
    "\n",
    "def logging_example_from_youtube():\n",
    "    \"\"\"https://github.com/CoreyMSchafer/code_snippets/blob/master/Logging-Advanced/employee.py\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    import pytorch_playground # has employee class & code\n",
    "    import sys\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n",
    "\n",
    "    file_handler = logging.FileHandler('sample.log')\n",
    "    file_handler.setLevel(logging.ERROR)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    logger.critical('not really critical :P')\n",
    "\n",
    "    def add(x, y):\n",
    "        \"\"\"Add Function\"\"\"\n",
    "        return x + y\n",
    "\n",
    "    def subtract(x, y):\n",
    "        \"\"\"Subtract Function\"\"\"\n",
    "        return x - y\n",
    "\n",
    "    def multiply(x, y):\n",
    "        \"\"\"Multiply Function\"\"\"\n",
    "        return x * y\n",
    "\n",
    "    def divide(x, y):\n",
    "        \"\"\"Divide Function\"\"\"\n",
    "        try:\n",
    "            result = x / y\n",
    "        except ZeroDivisionError:\n",
    "            logger.exception('Tried to divide by zero')\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "    logger.info('testing if log info is going to print to screen. it should because everything with debug or above is printed since that stream has that level.')\n",
    "\n",
    "    num_1 = 10\n",
    "    num_2 = 0\n",
    "\n",
    "    add_result = add(num_1, num_2)\n",
    "    logger.debug('Add: {} + {} = {}'.format(num_1, num_2, add_result))\n",
    "\n",
    "    sub_result = subtract(num_1, num_2)\n",
    "    logger.debug('Sub: {} - {} = {}'.format(num_1, num_2, sub_result))\n",
    "\n",
    "    mul_result = multiply(num_1, num_2)\n",
    "    logger.debug('Mul: {} * {} = {}'.format(num_1, num_2, mul_result))\n",
    "\n",
    "    div_result = divide(num_1, num_2)\n",
    "    logger.debug('Div: {} / {} = {}'.format(num_1, num_2, div_result))\n",
    "\n",
    "def plot():\n",
    "    \"\"\"\n",
    "    source:\n",
    "        - https://www.youtube.com/watch?v=UO98lJQ3QGI\n",
    "        - https://github.com/CoreyMSchafer/code_snippets/blob/master/Python/Matplotlib/01-Introduction/finished_code.py\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    plt.xkcd()\n",
    "\n",
    "    ages_x = [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
    "            36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
    "\n",
    "    py_dev_y = [20046, 17100, 20000, 24744, 30500, 37732, 41247, 45372, 48876, 53850, 57287, 63016, 65998, 70003, 70000, 71496, 75370, 83640, 84666,\n",
    "                84392, 78254, 85000, 87038, 91991, 100000, 94796, 97962, 93302, 99240, 102736, 112285, 100771, 104708, 108423, 101407, 112542, 122870, 120000]\n",
    "    plt.plot(ages_x, py_dev_y, label='Python')\n",
    "\n",
    "    js_dev_y = [16446, 16791, 18942, 21780, 25704, 29000, 34372, 37810, 43515, 46823, 49293, 53437, 56373, 62375, 66674, 68745, 68746, 74583, 79000,\n",
    "                78508, 79996, 80403, 83820, 88833, 91660, 87892, 96243, 90000, 99313, 91660, 102264, 100000, 100000, 91660, 99240, 108000, 105000, 104000]\n",
    "    plt.plot(ages_x, js_dev_y, label='JavaScript')\n",
    "\n",
    "    dev_y = [17784, 16500, 18012, 20628, 25206, 30252, 34368, 38496, 42000, 46752, 49320, 53200, 56000, 62316, 64928, 67317, 68748, 73752, 77232,\n",
    "            78000, 78508, 79536, 82488, 88935, 90000, 90056, 95000, 90000, 91633, 91660, 98150, 98964, 100000, 98988, 100000, 108923, 105000, 103117]\n",
    "    plt.plot(ages_x, dev_y, color='#444444', linestyle='--', label='All Devs')\n",
    "\n",
    "    plt.xlabel('Ages')\n",
    "    plt.ylabel('Median Salary (USD)')\n",
    "    plt.title('Median Salary (USD) by Age')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('plot.png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def subplot():\n",
    "    \"\"\"https://github.com/CoreyMSchafer/code_snippets/blob/master/Python/Matplotlib/10-Subplots/finished_code.py\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    data = pd.read_csv('data.csv')\n",
    "    ages = data['Age']\n",
    "    dev_salaries = data['All_Devs']\n",
    "    py_salaries = data['Python']\n",
    "    js_salaries = data['JavaScript']\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    fig2, ax2 = plt.subplots()\n",
    "\n",
    "    ax1.plot(ages, dev_salaries, color='#444444',\n",
    "            linestyle='--', label='All Devs')\n",
    "\n",
    "    ax2.plot(ages, py_salaries, label='Python')\n",
    "    ax2.plot(ages, js_salaries, label='JavaScript')\n",
    "\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Median Salary (USD) by Age')\n",
    "    ax1.set_ylabel('Median Salary (USD)')\n",
    "\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel('Ages')\n",
    "    ax2.set_ylabel('Median Salary (USD)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig1.savefig('fig1.png')\n",
    "    fig2.savefig('fig2.png')\n",
    "\n",
    "def import_utils_test():\n",
    "    import uutils\n",
    "    import uutils.utils as utils\n",
    "    from uutils.utils import logger\n",
    "\n",
    "    print(uutils)\n",
    "    print(utils)\n",
    "    print(logger)\n",
    "\n",
    "    print()\n",
    "\n",
    "def sys_path():\n",
    "    \"\"\"\n",
    "\n",
    "    python -c \"import sys; print(sys.path)â€\n",
    "\n",
    "    python -c \"import sys; [print(p) for p in sys.path]\"\n",
    "    \"\"\"\n",
    "    import sys\n",
    "\n",
    "    def path():\n",
    "        import sys\n",
    "        [print(p) for p in sys.path]\n",
    "\n",
    "    for path in sys.path:\n",
    "        print(path)\n",
    "\n",
    "def pycharm_playground():\n",
    "    import tqdm\n",
    "\n",
    "    print('running pycharm playground...')\n",
    "\n",
    "    b = 0\n",
    "    print(b)\n",
    "    print('Intermediate print line')\n",
    "    print(b)\n",
    "    print(b)\n",
    "    print('Done!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #union_dicts()\n",
    "    #get_stdout()\n",
    "    #logger()\n",
    "    #logger_SO_print_and_write_to_my_stdout()\n",
    "    #logging_basic()\n",
    "    #logging_to_file()\n",
    "    #logging_to_file()\n",
    "    #logging_to_file_INFO_LEVEL()\n",
    "    #logging_example_from_youtube()\n",
    "    #logging_unset_level()\n",
    "    #import_utils_test()\n",
    "    pycharm_playground()\n",
    "    print('\\n---> DONE\\a\\n\\n') ## HIii\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## dictionary comprehension looping\n",
    "\n",
    "d = {'a': 0, 'b': 1}\n",
    "lst1 = [f'key:{k}' for k in d]\n",
    "lst2 = [f'key:{k}, value:{v}' for k,v in d.items()]\n",
    "\n",
    "print(lst1)\n",
    "print(lst2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## merging two dictionaries\n",
    "\n",
    "d1 = {'a':0,'b':1}\n",
    "d2 = {'c':2,'d':3}\n",
    "d3 = {'e':4, 'f':5, 'g':6}\n",
    "d = {**d1, **d2, **d3}\n",
    "\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "od = OrderedDict([\n",
    "    ('first',1)\n",
    "])\n",
    "\n",
    "print(od)\n",
    "od['first'] = 2\n",
    "print(od)\n",
    "\n",
    "lst = sum( [i for i in range(3)] )\n",
    "print(lst)\n",
    "od3 = OrderedDict( [ (i,i) for i in range(3)] )\n",
    "print(od3)\n",
    "print(3+float('Inf'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "def make_dirpath_current_datetime_hostname(path=None, comment='', replace_dots=True):\n",
    "    '''\n",
    "    make dir string: runs/CURRENT_DATETIME_HOSTNAME\n",
    "    '''\n",
    "    import socket\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    # check if root is a PosixPath object\n",
    "    if type(path) != pathlib.PosixPath and path is not None:\n",
    "        path = Path(path)\n",
    "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    log_dir = os.path.join('runs', current_time + '_' + socket.gethostname() + comment)\n",
    "    log_dir = Path(log_dir)\n",
    "    print(log_dir._str)\n",
    "    if replace_dots:\n",
    "        log_dir = Path(log_dir._str.replace('.','_'))\n",
    "    if path is not None:\n",
    "        log_dir = path / log_dir\n",
    "    return log_dir\n",
    "\n",
    "print(type(Path('~')) == pathlib.PosixPath)\n",
    "print()\n",
    "\n",
    "log_dir = make_dirpath_current_datetime_hostname()\n",
    "print(log_dir)\n",
    "log_dir = make_dirpath_current_datetime_hostname('~')\n",
    "print(log_dir)\n",
    "log_dir = make_dirpath_current_datetime_hostname('~','_jupyter')\n",
    "print(log_dir)\n",
    "log_dir = make_dirpath_current_datetime_hostname('~').expanduser()\n",
    "print(log_dir)\n",
    "\n",
    "string = \"geeks for geeks geeks geeks geeks\"\n",
    "# Prints the string by replacing geeks by Geeks\n",
    "print( string.replace(\"geeks\", \"Geeks\") )\n",
    "\n",
    "log_dir = make_dirpath_current_datetime_hostname('~','_jupyter',True)\n",
    "print(log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adding keys to empty dic\n",
    "\n",
    "d = {}\n",
    "d['a'] = 3\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unpack list?\n",
    "\n",
    "(a,b,c) = [1,2,3]\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## kwargs\n",
    "\n",
    "def f(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "\n",
    "f()\n",
    "f(1,2,3,a=1,b=2,c=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path('~/')\n",
    "with open(p) as f:\n",
    "  data = json.load(f)\n",
    "  print(data)\n",
    "  print(data['password'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "cmd = 'ls /etc/fstab /etc/non-existent-file'\n",
    "p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)\n",
    "output = p.stdout.read()\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print('a')\n",
    "\n",
    "print(sys.stdout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def send_email(subject, message, destination, password_path=None):\n",
    "    \"\"\" Send an e-mail from with message to destination email.\n",
    "\n",
    "    NOTE: if you get an error with google gmails you might need to do this:\n",
    "    https://stackoverflow.com/questions/16512592/login-credentials-not-working-with-gmail-smtp\n",
    "    To use an app password:\n",
    "    https://stackoverflow.com/questions/60975490/how-does-one-send-an-e-mail-from-python-not-using-gmail\n",
    "\n",
    "    Arguments:\n",
    "        message {str} -- message string to send.\n",
    "        destination {str} -- destination email (as string)\n",
    "    \"\"\"\n",
    "    from socket import gethostname\n",
    "    from email.message import EmailMessage\n",
    "    import smtplib\n",
    "    import json\n",
    "    import sys\n",
    "\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    smtplib.stdout = sys.stdout\n",
    "    server.starttls()\n",
    "    with open(password_path) as f:\n",
    "        config = json.load(f)\n",
    "        server.login('slurm.miranda@gmail.com', config['password'])\n",
    "\n",
    "        # craft message\n",
    "        msg = EmailMessage()\n",
    "\n",
    "        #message = f'{message}\\nSend from Hostname: {gethostname()}'\n",
    "        #msg.set_content(message)\n",
    "        msg['Subject'] = subject\n",
    "        msg['From'] = 'slurm.miranda@gmail.com'\n",
    "        msg['To'] = destination\n",
    "        # send msg\n",
    "        server.send_message(msg)\n",
    "\n",
    "##\n",
    "print(\"-------> HELLOWWWWWWWW\")\n",
    "p = Path('~/automl-meta-learning/automl/experiments/pw_app.config.json').expanduser()\n",
    "send_email(subject='TEST: send_email2', message='MESSAGE', destination='brando.science@gmail.com', password_path=p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo of the errorbar function, including upper and lower limits\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"errorbar.capsize\"] = 3\n",
    "\n",
    "# https://stackoverflow.com/questions/61415955/why-dont-the-error-limits-in-my-plots-show-in-matplotlib\n",
    "\n",
    "# example data\n",
    "x = np.arange(0.5, 5.5, 0.5)\n",
    "y = np.exp(-x)\n",
    "xerr = 0.1\n",
    "yerr = 0.2\n",
    "ls = 'dotted'\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# standard error bars\n",
    "plt.errorbar(x, y, xerr=xerr, yerr=yerr, ls=ls, color='blue')\n",
    "\n",
    "# including upper limits\n",
    "uplims = np.zeros(x.shape)\n",
    "uplims[[1, 5, 9]] = True\n",
    "plt.errorbar(x, y + 0.5, xerr=xerr, yerr=yerr, uplims=uplims, ls=ls,\n",
    "             color='green')\n",
    "\n",
    "# including lower limits\n",
    "lolims = np.zeros(x.shape)\n",
    "lolims[[2, 4, 8]] = True\n",
    "plt.errorbar(x, y + 1.0, xerr=xerr, yerr=yerr, lolims=lolims, ls=ls,\n",
    "             color='red')\n",
    "\n",
    "# including upper and lower limits\n",
    "plt.errorbar(x, y + 1.5, marker='o', ms=8, xerr=xerr, yerr=yerr,\n",
    "             lolims=lolims, uplims=uplims, ls=ls, color='magenta')\n",
    "\n",
    "# including xlower and xupper limits\n",
    "xerr = 0.2\n",
    "yerr = np.zeros(x.shape) + 0.2\n",
    "yerr[[3, 6]] = 0.3\n",
    "xlolims = lolims\n",
    "xuplims = uplims\n",
    "lolims = np.zeros(x.shape)\n",
    "uplims = np.zeros(x.shape)\n",
    "lolims[[6]] = True\n",
    "uplims[[3]] = True\n",
    "plt.errorbar(x, y + 2.1, marker='o', ms=8, xerr=xerr, yerr=yerr,\n",
    "             xlolims=xlolims, xuplims=xuplims, uplims=uplims, lolims=lolims,\n",
    "             ls='none', mec='blue', capsize=0, color='cyan')\n",
    "\n",
    "ax.set_xlim((0, 5.5))\n",
    "ax.set_title('Errorbar upper and lower limits')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "args = SimpleNamespace()\n",
    "args.data_root = \"~/automl-meta-learning/data/miniImagenet\"\n",
    "\n",
    "args.data_root = Path(args.data_root).expanduser()\n",
    "\n",
    "print(args)\n",
    "\n",
    "#pprint(dir(args.data_root))\n",
    "print(args.data_root.name)\n",
    "print('miniImagenet' in args.data_root.name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## sampling N classes for len(meta-set)\n",
    "# In sampling without replacement, each sample unit of\n",
    "# the population has only one chance to be selected in the sample.\n",
    "# because you are NOT replacing what you removed.\n",
    "\n",
    "import random\n",
    "\n",
    "N = 5\n",
    "len_meta_set = 64\n",
    "sample = random.sample(range(0, len_meta_set), N)\n",
    "\n",
    "print( sample )\n",
    "\n",
    "for i,n in enumerate(sample):\n",
    "    print(f'i={i}\\nn={n}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterator https://www.programiz.com/python-programming/iterator\n",
    "\n",
    "class Counter:\n",
    "\n",
    "    def __init__(self, max=0):\n",
    "        self.max = max # returns up to and including that number\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n <= self.max:\n",
    "            current_count = self.n\n",
    "            self.n += 1\n",
    "            print(f'current_count = {current_count}')\n",
    "            print(f'self.n = {self.n}')\n",
    "            print(self.n is current_count)\n",
    "            return current_count\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "## test it\n",
    "\n",
    "counter = iter(Counter(max=0))\n",
    "for count in counter:\n",
    "    print(f'count = {count}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(tqdm)\n",
    "\n",
    "lst = range(3)\n",
    "print(type(lst))\n",
    "\n",
    "with tqdm(iter(lst), total=5) as tlist:\n",
    "    print(f'tlist = {type(tlist)}')\n",
    "    for i in tlist:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Plus2:\n",
    "\n",
    "    def __init__(self, max=0):\n",
    "        self.max = max # returns up to and including that number\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.it = 0\n",
    "        self.tot = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.it <= self.max:\n",
    "            self.it += 1\n",
    "            self.tot += 2\n",
    "            return self.tot\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max\n",
    "\n",
    "##\n",
    "counter = iter(Plus2(max=int(100000)))\n",
    "with tqdm(counter, total=len(counter)) as tqcounter:\n",
    "    for idx, pow2 in enumerate(tqcounter):\n",
    "        print()\n",
    "        print(f'idx = {idx}')\n",
    "        print(f'powd2 = {pow2}')\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(int(9e6))):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "with tqdm(range(int(5))) as trange:\n",
    "    for i in trange:\n",
    "        print(f'\\ni = {i}')\n",
    "        print('done\\n')\n",
    "        time.sleep(1)\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#zip, it aligns elements in one list to elements in the other\n",
    "\n",
    "l1 = [0,1,2]\n",
    "l2 = ['a','b','c']\n",
    "\n",
    "print(list(zip(l1,l2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "lst = range(10000000)\n",
    "total = 2\n",
    "\n",
    "with tqdm(lst, total=total) as tlst:\n",
    "    i = 0\n",
    "    for _, element in enumerate(tlst):\n",
    "        print(f'\\n->i = {i}\\n')\n",
    "        time.sleep(0.2)\n",
    "        i += 1\n",
    "        if i >= total:\n",
    "            break\n",
    "\n",
    "print('\\n--> DONE \\a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "lst = range(10000000)\n",
    "total = 2\n",
    "\n",
    "with tqdm(lst, total=total) as tlst:\n",
    "    for idx, element in enumerate(tlst):\n",
    "        print(f'\\n->idx = {idx}\\n')\n",
    "        time.sleep(0.2)\n",
    "        if idx >= total:\n",
    "            break\n",
    "\n",
    "print('\\n--> DONE \\a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "lst = range(10000000)\n",
    "total = 2\n",
    "\n",
    "with tqdm(range(total)) as tcounter:\n",
    "    lst = iter(lst)\n",
    "    for idx, element in enumerate(tcounter):\n",
    "        print(f'\\n->idx = {idx}\\n')\n",
    "        time.sleep(0.2)\n",
    "\n",
    "print('\\n--> DONE \\a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Question: Do detached() tensors track their own gradients seperately?\n",
    "# Ans: Yes!\n",
    "# https://discuss.pytorch.org/t/why-is-the-clone-operation-part-of-the-computation-graph-is-it-even-differentiable/67054/11\n",
    "\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([2.0], requires_grad=True)\n",
    "b = a.detach()\n",
    "b.requires_grad = True\n",
    "\n",
    "la = (5.0 - a)**2\n",
    "la.backward()\n",
    "print(f'a.grad = {a.grad}')\n",
    "\n",
    "lb = (6.0 - b)**2\n",
    "lb.backward()\n",
    "print(f'b.grad = {b.grad}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "params = OrderedDict([\n",
    "    ('fc0', nn.Linear(in_features=4,out_features=4)),\n",
    "    ('ReLU0', nn.ReLU()),\n",
    "    ('fc1', nn.Linear(in_features=4,out_features=1))\n",
    "])\n",
    "mdl = nn.Sequential(params)\n",
    "\n",
    "print(params)\n",
    "print(mdl._parameters)\n",
    "print(params == params)\n",
    "print(mdl._parameters == params)\n",
    "print(mdl._modules)\n",
    "\n",
    "print()\n",
    "for name, w in mdl.named_parameters():\n",
    "    print(name, w.norm(2))\n",
    "\n",
    "print()    \n",
    "#mdl._modules['fc0'] = nn.Linear(10,11)\n",
    "mdl._modules[0]\n",
    "\n",
    "for name, w in mdl.named_parameters():\n",
    "    print(name, w.norm(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Q: are parameters are in computation graph?\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "fc0 = nn.Linear(in_features=3,out_features=1)\n",
    "params = [('fc0', fc0)]\n",
    "mdl = nn.Sequential(OrderedDict(params))\n",
    "\n",
    "x = torch.randn(1,3)\n",
    "y = torch.randn(1)\n",
    "\n",
    "l = ( mdl(x) - y )**2\n",
    "\n",
    "# make_dot(l,{x:'x',y:'y','fc0':fc0})\n",
    "print(fc0.weight)\n",
    "print(fc0.bias)\n",
    "print(fc0.weight.to_tens)\n",
    "print()\n",
    "# make_dot(l,{x:'x',y:'y','fc0':fc0})\n",
    "make_dot(l,{'x':x,'y':y})\n",
    "make_dot(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "expand\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn([2,3,4,5])\n",
    "\n",
    "# h_0 of shape (num_layers * num_directions, batch, hidden_size)\n",
    "h = torch.randn([1,4,8])\n",
    "\n",
    "x_mean = x.mean()\n",
    "print(x_mean.size())\n",
    "print(x_mean)\n",
    "x = x_mean.expand_as(h)\n",
    "print(x.size())\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "type(device)\n",
    "print(device == 'cpu')\n",
    "device.type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# THIS WORKS\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#log_dir (string) â€“ Save directory location. \n",
    "#Default is runs/CURRENT_DATETIME_HOSTNAME, which changes after each run.\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_scalar('loss', 111)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def CURRENT_DATETIME_HOSTNAME(comment=''):\n",
    "    #if not log_dir:\n",
    "    import socket\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    log_dir = os.path.join('runs', current_time + '_' + socket.gethostname() + comment)\n",
    "    return Path(log_dir)\n",
    "\n",
    "#log_dir (string) â€“ Save directory location. \n",
    "#Default is runs/CURRENT_DATETIME_HOSTNAME, which changes after each run.\n",
    "# tensorboard --logdir=runs\n",
    "log_dir = (Path('~/automl-meta-learning/') / CURRENT_DATETIME_HOSTNAME()).expanduser()\n",
    "print(log_dir)\n",
    "tb = SummaryWriter(log_dir=log_dir)\n",
    "tb.add_scalar('loss', 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# download mini-imagenet automatically\n",
    "\n",
    "#from torchvision.utils import download_and_extract_archive\n",
    "\n",
    "import torchvision.utils as utils\n",
    "\n",
    "print(utils)\n",
    "#print(download_and_extract_archive)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#torch concat, https://pytorch.org/docs/stable/torch.html#torch.cat\n",
    "# Concatenates the given sequence of seq tensors in the given dimension. \n",
    "# All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n",
    "import torch\n",
    "\n",
    "g1 = torch.randn(3,2)\n",
    "g2 = torch.randn(4,2)\n",
    "\n",
    "g3 = torch.randn(4,2,3)\n",
    "\n",
    "grads = [g1, g2]\n",
    "print(g1.view(-1).size())\n",
    "print(g2.view(-1).size())\n",
    "print(g3.view(-1).size())\n",
    "#print(g3.view(-1))\n",
    "\n",
    "grads = torch.cat(grads, dim=0)\n",
    "print(grads)\n",
    "print(grads.size())\n",
    "print(grads.mean())\n",
    "print(grads.std())\n",
    "\n",
    "# torch stack, https://pytorch.org/docs/stable/torch.html#torch.stack\n",
    "# Concatenates sequence of tensors along a new dimension. \n",
    "# All tensors need to be of the same size.\n",
    "# torch.stack([g1,g2], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1,2,3.], requires_grad=True)\n",
    "a_detached = a.detach()\n",
    "print(a_detached.is_leaf)\n",
    "a_detached_sum = a.sum()\n",
    "print(c.is_leaf)\n",
    "d = c.detach()\n",
    "print(d.is_leaf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "x = torch.empty([1,2,3])\n",
    "print(x.size())\n",
    "\n",
    "args = SimpleNamespace()\n",
    "args.data_root = \"~/automl-meta-learning/data/miniImagenet\"\n",
    "\n",
    "#n1313361300001299.jpg\n",
    "args.data_root = Path(args.data_root).expanduser()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "CHW = 3,12,12\n",
    "x = torch.randn(CHW)\n",
    "y = torch.randn(CHW)\n",
    "\n",
    "new = [x,y]\n",
    "new = torch.stack(new)\n",
    "print(x.size())\n",
    "print(new.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('a');print('b')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# conver list to tensor\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3.])\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "    import torchmeta\n",
    "    from torchmeta.datasets.helpers import miniimagenet\n",
    "\n",
    "    from pathlib import Path\n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    ## get args\n",
    "    args = SimpleNamespace(episodes=5,n_classes=5,k_shot=5,k_eval=15,meta_batch_size=1,n_workers=4)\n",
    "    args.data_root = Path(\"~/automl-meta-learning/data/miniImagenet\").expanduser()\n",
    "\n",
    "    ## get meta-batch loader\n",
    "    train_transform = Compose([Resize(84), ToTensor()])\n",
    "    dataset = miniimagenet( \n",
    "        args.data_root, \n",
    "        ways=args.n_classes, \n",
    "        shots=args.k_shot, \n",
    "        test_shots=args.k_eval,\n",
    "        meta_split='train',\n",
    "        download=False)\n",
    "    dataloader = torchmeta.utils.data.BatchMetaDataLoader(\n",
    "        dataset, \n",
    "        batch_size=args.meta_batch_size,\n",
    "        num_workers=args.n_workers)\n",
    "\n",
    "    with tqdm(dataset):\n",
    "        print(f'len(dataloader)= {len(dataloader)}')\n",
    "        for episode, batch in enumerate(dataloader):\n",
    "            print(f'episode = {episode}') \n",
    "            train_inputs, train_labels = batch[\"train\"]\n",
    "            print(f'train_labels[0] = {train_labels[0]}')\n",
    "            print(f'train_inputs.size() = {train_inputs.size()}')\n",
    "            pass\n",
    "            if episode >= args.episodes:\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# zip tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([1.,2.,3.])\n",
    "y = torch.tensor([1,2,3])\n",
    "\n",
    "print(list(zip(x,y)))\n",
    "\n",
    "xx = torch.randn(2,3,84,84)\n",
    "yy = torch.randn(2,3,32,32)\n",
    "\n",
    "print(len(list(zip(xx,yy))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = 2\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## sinusioid function\n",
    "print('Starting Sinusioid cell')\n",
    "\n",
    "from torchmeta.toy import Sinusoid\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.transforms import ClassSplitter\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "batch_size=16\n",
    "shots = 5\n",
    "test_shots = 15\n",
    "# dataset = torchmeta.toy.helpers.sinusoid(shots=shots, test_shots=tes_shots)\n",
    "metaset_dataset = Sinusoid(num_samples_per_task=shots+test_shots, num_tasks=100, noise_std=None)\n",
    "splitter_metset_dataset = ClassSplitter(\n",
    "        metaset_dataset,\n",
    "        num_train_per_class=shots,\n",
    "        num_test_per_class=test_shots,\n",
    "        shuffle=True)\n",
    "dataloader = BatchMetaDataLoader(splitter_metset_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "print(f'batch_size = {batch_size}')\n",
    "print(f'len(dataset) = {len(metaset_dataset)}')\n",
    "print(f'len(dataloader) = {len(dataloader)}\\n')\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    print(f'batch_idx = {batch_idx}')\n",
    "    train_inputs, train_targets = batch['train']\n",
    "    test_inputs, test_targets = batch['test']\n",
    "    print(f'train_inputs.shape = {train_inputs.shape}')\n",
    "    print(f'train_targets.shape = {train_targets.shape}')\n",
    "    print(f'test_inputs.shape = {test_inputs.shape}')\n",
    "    print(f'test_targets.shape = {test_targets.shape}')\n",
    "    if batch_idx >= 1: # halt after 2 iterations\n",
    "        break\n",
    "\n",
    "print('DONE\\a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## notes of torchmeta\n",
    "\n",
    "from pathlib import Path\n",
    "import torchmeta\n",
    "\n",
    "# meta-set: creates collection of data-sets, D_meta = {D_1, ... Dn}\n",
    "print('\\n-- Sinusoid(MetaDataset)')\n",
    "metaset_sinusoid = torchmeta.toy.Sinusoid(num_samples_per_task=10, num_tasks=1_000_000, noise_std=None)\n",
    "print(f'type(metaset_sinusoid) = {type(metaset_sinusoid)}')\n",
    "print(f'len(metaset_sinusoid) = {len(metaset_sinusoid)}')\n",
    "print(f'metaset_sinusoid = {metaset_sinusoid}')\n",
    "\n",
    "# this is still a data set but helps implement forming D_i\n",
    "# i.e. the N-way, K-shot tasks/datasets we need.\n",
    "print('\\n-- MiniImagenet(CombinationMetaDataset)')\n",
    "data_path = Path('~/data').expanduser()\n",
    "metaset_miniimagenet = torchmeta.datasets.MiniImagenet(data_path, num_classes_per_task=5, meta_train=True, download=True)\n",
    "print(f'type(metaset_miniimagenet) = {type(metaset_miniimagenet)}')\n",
    "print(f'len(metaset_miniimagenet) = {len(metaset_miniimagenet)}')\n",
    "print(f'metaset_miniimagenet = {metaset_miniimagenet}')\n",
    "\n",
    "# Splits the data-sets inside the meta-set into support/train & query/test sets\n",
    "dataset = metaset_miniimagenet\n",
    "dataset = torchmeta.transforms.ClassSplitter(dataset, num_train_per_class=1, num_test_per_class=15, shuffle=True)\n",
    "print(dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.uniform()\n",
    "\n",
    "x = torch.rand()\n",
    "\n",
    "print(x)\n",
    "\n",
    "l = nn.Linear(1,1)\n",
    "\n",
    "y = l(x)\n",
    "\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# saving tensors for my data set\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# N x's of size D=1 in an interval\n",
    "Din,Dout = 3,2\n",
    "num_samples = 5\n",
    "lb,ub = -1,1\n",
    "X = (ub - lb) * torch.rand([num_samples,Din]) + lb  # rand gives uniform in [0,1) range\n",
    "\n",
    "# N y's of size D=1 (from output of NN)\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('f1', nn.Linear(Din,Dout)),\n",
    "    ('out', nn.SELU())\n",
    "]))\n",
    "\n",
    "# fill cnn with Gaussian\n",
    "mu1,std1 = 5,7.5\n",
    "f.f1.weight.data.normal_(mu1,std1)\n",
    "f.f1.bias.data.normal_(mu1,std1)\n",
    "\n",
    "# get outputs\n",
    "Y = f(X)\n",
    "print(Y)\n",
    "\n",
    "# save tensors and cnn\n",
    "# https://stackoverflow.com/questions/1466000/difference-between-modes-a-a-w-w-and-r-in-built-in-open-function\n",
    "db = {\n",
    "    'X':X,\n",
    "    'Y':Y\n",
    "}\n",
    "path = Path(f'~/data/tmp/SinData_mu1{mu1}_std1{std1}/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "with open(path / 'db','w') as file: # create file and truncate to length 0, only writing allowed\n",
    "    torch.save(db, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# saving data in numpy\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('~/data/tmp/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lb,ub = -1,1\n",
    "num_samples = 5\n",
    "x = np.random.uniform(low=lb,high=ub,size=(1,num_samples))\n",
    "y = x**2 + x + 2\n",
    "\n",
    "# using save (to npy), savez (to npz)\n",
    "np.save(path/'x', x)\n",
    "np.save(path/'y', y)\n",
    "np.savez(path/'db', x=x, y=y)\n",
    "with open(path/'db.pkl', 'wb') as db_file:\n",
    "    pickle.dump(obj={'x':x, 'y':y}, file=db_file)\n",
    "\n",
    "## using loading npy, npz files\n",
    "x_loaded = np.load(path/'x.npy')\n",
    "y_load = np.load(path/'y.npy')\n",
    "db = np.load(path/'db.npz')\n",
    "with open(path/'db.pkl', 'rb') as db_file:\n",
    "    db_pkl = pickle.load(db_file)\n",
    "\n",
    "print(x is x_loaded)\n",
    "print(x == x_loaded)\n",
    "print(x == db['x'])\n",
    "print(x == db_pkl['x'])\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('~/data/tmp/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lb,ub = -1,1\n",
    "num_samples = 5\n",
    "x = np.random.uniform(low=lb,high=ub,size=(1,num_samples))\n",
    "y = x**2 + x + 2\n",
    "\n",
    "np.save(path/'x', x)\n",
    "np.save(path/'y', y)\n",
    "\n",
    "x_loaded = np.load(path/'x.npy')\n",
    "y_load = np.load(path/'y.npy')\n",
    "\n",
    "print(x is x_loaded) # False\n",
    "print(x == x_loaded) # [[ True  True  True  True  True]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# saving torch tensors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "path = Path('~/data/tmp/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tensor_a = torch.rand(2,3)\n",
    "tensor_b = torch.rand(1,3)\n",
    "\n",
    "db = {'a': tensor_a, 'b': tensor_b}\n",
    "\n",
    "torch.save(db, path/'torch_db')\n",
    "loaded = torch.load(path/'torch_db')\n",
    "print( loaded['a'] == tensor_a )\n",
    "print( loaded['b'] == tensor_b )\n",
    "\n",
    "# testing if ToTensor() screws things up\n",
    "lb, ub = -1, 1\n",
    "N, Din, Dout = 3, 1, 1\n",
    "x = torch.distributions.Uniform(low=lb, high=ub).sample((N, Din))\n",
    "print(x)\n",
    "\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('f1', nn.Linear(Din,Dout)),\n",
    "    ('out', nn.SELU())\n",
    "]))\n",
    "y = f(x)\n",
    "\n",
    "transform = torchvision.transforms.transforms.ToTensor()\n",
    "y_proc = transform(y)\n",
    "print(y_proc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# union dictionaries, https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression-in-python\n",
    "\n",
    "d1 = {'a':1, 'b':2.5}\n",
    "d2 = {'b':2, 'c':3, 'd':4}\n",
    "d = {**d1, **d2}\n",
    "# duplicates resolved in favour of d2\n",
    "print(d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generating uniform variables\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 3\n",
    "Din = 1\n",
    "lb, ub = -1, 1\n",
    "\n",
    "xn = np.random.uniform(low=lb, high=ub, size=(num_samples,Din))\n",
    "print(xn)\n",
    "\n",
    "import torch\n",
    "\n",
    "sampler = torch.distributions.Uniform(low=lb, high=ub)\n",
    "r = sampler.sample((num_samples,Din))\n",
    "\n",
    "print(r)\n",
    "\n",
    "r2 = torch.torch.distributions.Uniform(low=lb, high=ub).sample((num_samples,Din))\n",
    "\n",
    "print(r2)\n",
    "\n",
    "# process input\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('f1', nn.Linear(Din,Dout)),\n",
    "    ('out', nn.SELU())\n",
    "]))\n",
    "Y = f(r2)\n",
    "print(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sampling from normal distribution in torch\n",
    "\n",
    "import torch\n",
    "\n",
    "num_samples = 3\n",
    "Din = 1\n",
    "mu, std = 0, 1\n",
    "x = torch.distributions.normal.Normal(loc=mu, scale=std).sample((num_samples, Din))\n",
    "\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating data and running through a nn and saving it\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "path = Path('~/data/tmp/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_samples = 3\n",
    "Din, Dout = 1, 1\n",
    "lb, ub = -1, 1\n",
    "\n",
    "x = torch.torch.distributions.Uniform(low=lb, high=ub).sample((num_samples, Din))\n",
    "\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('f1', nn.Linear(Din,Dout)),\n",
    "    ('out', nn.SELU())\n",
    "]))\n",
    "y = f(x)\n",
    "\n",
    "# save data torch to numpy\n",
    "x_np, y_np = x.detach().cpu().numpy(), y.detach().cpu().numpy()\n",
    "np.savez(path / 'db', x=x_np, y=y_np)\n",
    "\n",
    "print(x_np)\n",
    "# save model\n",
    "with open('db_saving_seq', 'wb') as file:\n",
    "    pickle.dump({'f': f}, file)\n",
    "\n",
    "# load model\n",
    "with open('db_saving_seq', 'rb') as file:\n",
    "    db = pickle.load(file)\n",
    "    f2 = db['f']\n",
    "\n",
    "# test that it outputs the right thing\n",
    "y2 = f2(x)\n",
    "\n",
    "y_eq_y2 = y == y2\n",
    "print(y_eq_y2)\n",
    "\n",
    "db2 = {'f': f, 'x': x, 'y': y}\n",
    "torch.save(db2, path / 'db_f_x_y')\n",
    "\n",
    "print('Done')\n",
    "\n",
    "db3 = torch.load(path / 'db_f_x_y')\n",
    "f3 = db3['f']\n",
    "x3 = db3['x']\n",
    "y3 = db3['y']\n",
    "yy3 = f3(x3)\n",
    "\n",
    "y_eq_y3 = y == y3\n",
    "print(y_eq_y3)\n",
    "\n",
    "y_eq_yy3 = y == yy3\n",
    "print(y_eq_yy3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test for saving everything with torch.save\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "path = Path('~/data/tmp/').expanduser()\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_samples = 3\n",
    "Din, Dout = 1, 1\n",
    "lb, ub = -1, 1\n",
    "\n",
    "x = torch.torch.distributions.Uniform(low=lb, high=ub).sample((num_samples, Din))\n",
    "\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('f1', nn.Linear(Din,Dout)),\n",
    "    ('out', nn.SELU())\n",
    "]))\n",
    "y = f(x)\n",
    "\n",
    "# save data torch to numpy\n",
    "x_np, y_np = x.detach().cpu().numpy(), y.detach().cpu().numpy()\n",
    "db2 = {'f': f, 'x': x_np, 'y': y_np}\n",
    "torch.save(db2, path / 'db_f_x_y')\n",
    "# np.savetxt(path / 'output.csv', y_np)  # for csv\n",
    "\n",
    "db3 = torch.load(path / 'db_f_x_y')\n",
    "f3 = db3['f']\n",
    "x3 = db3['x']\n",
    "y3 = db3['y']\n",
    "xx = torch.tensor(x3)\n",
    "yy3 = f3(xx)\n",
    "\n",
    "print(yy3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# my saving code for synthetic data, nvm using torch.save for everything\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "#\n",
    "# from pathlib import Path\n",
    "# from collections import OrderedDict\n",
    "#\n",
    "# import numpy as np\n",
    "#\n",
    "# path = Path('~/data/tmp/').expanduser()\n",
    "# path.mkdir(parents=True, exist_ok=True)\n",
    "#\n",
    "# num_samples = 3\n",
    "# Din, Dout = 1, 1\n",
    "# lb, ub = -1, 1\n",
    "#\n",
    "# x = torch.torch.distributions.Uniform(low=lb, high=ub).sample((num_samples, Din))\n",
    "#\n",
    "# f = nn.Sequential(OrderedDict([\n",
    "#     ('f1', nn.Linear(Din,Dout)),\n",
    "#     ('out', nn.SELU())\n",
    "# ]))\n",
    "# y = f(x)\n",
    "#\n",
    "# # save data torch to numpy\n",
    "# x_np, y_np = x.detach().cpu().numpy(), y.detach().cpu().numpy()\n",
    "# np.savez(path / 'data', x=x_np, y=y_np)\n",
    "#\n",
    "# # save model\n",
    "# torch.save(f,path / 'f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "num_samples = 3\n",
    "Din, Dout = 1, 1\n",
    "lb, ub = -1, 1\n",
    "\n",
    "x = torch.torch.distributions.Uniform(low=lb, high=ub).sample((num_samples, Din))\n",
    "\n",
    "hidden_dim = [(Din, 20), (20, 20), (20, 20), (20, 20), (20, Dout)]\n",
    "f = nn.Sequential(OrderedDict([\n",
    "    ('fc1;l1', nn.Linear(hidden_dim[0][0], hidden_dim[0][1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc2;l1', nn.Linear(hidden_dim[1][0], hidden_dim[1][1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc3;l1', nn.Linear(hidden_dim[2][0], hidden_dim[2][1])),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('fc4;l1', nn.Linear(hidden_dim[3][0], hidden_dim[3][1])),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('fc5;final;l2', nn.Linear(hidden_dim[4][0], hidden_dim[4][1]))\n",
    "]))\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "section_label = [1]*4 + [2]\n",
    "print(section_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get list of paths to task\n",
    "# https://stackoverflow.com/questions/973473/getting-a-list-of-all-subdirectories-in-the-current-directory\n",
    "# https://stackoverflow.com/a/44228436/1601580\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "meta_split = 'train'\n",
    "data_path = Path('~/data/LS/debug/fully_connected_NN_mu1_1.0_std1_2.5_mu2_1.0_std2_0.5/')\n",
    "data_path = (data_path / meta_split).expanduser()\n",
    "\n",
    "# with path lib\n",
    "tasks_folder = [f for f in data_path.iterdir() if f.is_dir()]\n",
    "\n",
    "assert('f_avg' not in tasks_folder)\n",
    "\n",
    "len_folder = len(tasks_folder)\n",
    "print(len_folder)\n",
    "print(tasks_folder)\n",
    "print()\n",
    "\n",
    "# with glob\n",
    "p = str(data_path) + '/*/'\n",
    "print(p)\n",
    "tasks_folder = glob( p )\n",
    "\n",
    "assert('f_avg' not in tasks_folder)\n",
    "\n",
    "len_folder = len(tasks_folder)\n",
    "print(len_folder)\n",
    "print(tasks_folder)\n",
    "print()\n",
    "\n",
    "# with glob and negation\n",
    "print( set(glob(str(data_path / \"f_avg\"))) )\n",
    "tasks_folder = set(glob(str(data_path / '*'))) - set(glob(str(data_path / \"f_avg\")))\n",
    "\n",
    "assert('f_avg' not in tasks_folder)\n",
    "\n",
    "len_folder = len(tasks_folder)\n",
    "print(len_folder)\n",
    "print(tasks_folder)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# looping through metasets\n",
    "\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.transforms import ClassSplitter\n",
    "from torchmeta.toy import Sinusoid\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get data set\n",
    "dataset = Sinusoid(num_samples_per_task=25, num_tasks=30)\n",
    "shots, test_shots = 5, 15\n",
    "# get metaset\n",
    "metaset = ClassSplitter(\n",
    "    dataset,\n",
    "    num_train_per_class=shots,\n",
    "    num_test_per_class=test_shots,\n",
    "    shuffle=True)\n",
    "# get meta-dataloader\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "meta_dataloader = BatchMetaDataLoader(metaset, batch_size=batch_size, num_workers=num_workers)\n",
    "epochs = 2\n",
    "\n",
    "print(f'batch_size = {batch_size}')\n",
    "print(f'len(metaset) = {len(metaset)}')\n",
    "print(f'len(meta_dataloader) = {len(meta_dataloader)}')\n",
    "with tqdm(range(epochs)) as tepochs:\n",
    "    for epoch in tepochs:\n",
    "        for batch_idx, batch in enumerate(meta_dataloader):\n",
    "            print(f'\\nbatch_idx = {batch_idx}')\n",
    "            train_inputs, train_targets = batch['train']\n",
    "            test_inputs, test_targets = batch['test']\n",
    "            print(f'train_inputs.shape = {train_inputs.shape}')\n",
    "            print(f'train_targets.shape = {train_targets.shape}')\n",
    "            print(f'test_inputs.shape = {test_inputs.shape}')\n",
    "            print(f'test_targets.shape = {test_targets.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "with tqdm(range(5)) as trange:\n",
    "    for t in trange:\n",
    "        print(t)\n",
    "        time.sleep(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "l1 = torch.tensor([1,2,3.])**0.5\n",
    "l2 = torch.tensor([0,0,0.0])\n",
    "mse = nn.MSELoss()\n",
    "loss = mse(l1,l2)\n",
    "print(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.arange(0,10)\n",
    "print(x)\n",
    "\n",
    "print(x.max())\n",
    "print(x.min())\n",
    "print(x.mean())\n",
    "print(np.median(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.randn(3)\n",
    "print(x)\n",
    "print(x.argmax(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing accuracy function\n",
    "# https://discuss.pytorch.org/t/calculating-accuracy-of-the-current-minibatch/4308/11\n",
    "# https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "D = 1\n",
    "true = torch.tensor([0,1,0,1,1]).reshape(5,1)\n",
    "print(f'true.size() = {true.size()}')\n",
    "\n",
    "batch_size = true.size(0)\n",
    "print(f'batch_size = {batch_size}')\n",
    "x = torch.randn(batch_size,D)\n",
    "print(f'x = {x}')\n",
    "print(f'x.size() = {x.size()}')\n",
    "\n",
    "mdl = nn.Linear(D,1)\n",
    "logit = mdl(x)\n",
    "_, pred = torch.max(logit.data, 1)\n",
    "\n",
    "print(f'logit = {logit}')\n",
    "\n",
    "print(f'pred = {pred}')\n",
    "print(f'true = {true}')\n",
    "\n",
    "acc = (true == pred).sum().item()\n",
    "print(f'acc = {acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be\n",
    "# dimension\n",
    "# https://discuss.pytorch.org/t/how-does-one-get-the-predicted-classification-label-from-a-pytorch-model/91649/4?u=brando_miranda\n",
    "\"\"\"\n",
    "Dimension reduction. It collapses/reduces a specific dimension by selecting an element from that dimension to be\n",
    "reduced.\n",
    "Consider x is 3D tensor. x.sum(1) converts x into a tensor that is 2D using an element from D1 elements in\n",
    "the 1th dimension. Thus:\n",
    "x.sum(1) = x[i,k] = op(x[i,:,k]) = op(x[i,0,k],...,x[i,D1,k])\n",
    "the key is to realize that we need 3 indices to select a single element. So if we use only 2 (because we are collapsing)\n",
    "then we have D1 number of elements possible left that those two indices might indicate. So from only 2 indices we get a\n",
    "set that we need to specify how to select. This is where the op we are using is used for and selects from this set.\n",
    "In theory if we want to collapse many indices we need to indicate how we are going to allow indexing from a smaller set\n",
    "of indices (using the remaining set that we'd usually need).\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([\n",
    "     [1, 2, 3],\n",
    "     [4, 5, 6]\n",
    "   ])\n",
    "\n",
    "print(f'x.size() = {x.size()}')\n",
    "\n",
    "# sum the 0th dimension (rows). So we get a bunch of colums that have the rows added together.\n",
    "x0 = x.sum(0)\n",
    "print(x0)\n",
    "\n",
    "# sum the 1th dimension (columns)\n",
    "x1 = x.sum(1)\n",
    "print(x1)\n",
    "\n",
    "x_1 = x.sum(-1)\n",
    "print(x_1)\n",
    "\n",
    "x0 = x.max(0)\n",
    "print(x0.values)\n",
    "\n",
    "y = torch.tensor([[\n",
    "         [ 1,  2,  3,  4],\n",
    "         [ 5,  6,  7,  8],\n",
    "         [ 9, 10, 11, 12]],\n",
    "\n",
    "        [[13, 14, 15, 16],\n",
    "         [17, 18, 19, 20],\n",
    "         [21, 22, 23, 24]]])\n",
    "\n",
    "print(y)\n",
    "\n",
    "# into the screen [1, 13]\n",
    "print(y[:,0,0])\n",
    "# columns [1, 5, 9]\n",
    "print(y[0,:,0])\n",
    "# rows [1, 2, 3, 4]\n",
    "print(y[0,0,:])\n",
    "\n",
    "# for each remaining index, select the largest value in the \"screen\" dimension\n",
    "y0 = y.max(0)\n",
    "print(y0.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# understanding making label predictions\n",
    "# https://discuss.pytorch.org/t/how-does-one-get-the-predicted-classification-label-from-a-pytorch-model/91649/3?u=brando_miranda\n",
    "\n",
    "def calc_accuracy(mdl, X, Y):\n",
    "    # reduce/collapse the classification dimension according to max op\n",
    "    # resulting in most likely label\n",
    "    max_vals, max_indices = mdl(X).max(1)\n",
    "    # assumes the first dimension is batch size\n",
    "    n = max_indices.size(0)  # index 0 for extracting the # of elements\n",
    "    # calulate acc (note .item() to do float division)\n",
    "    acc = (max_indices == Y).sum().item() / n\n",
    "    return acc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# data dimension [batch-size, D]\n",
    "D, Dout = 1, 5\n",
    "batch_size = 16\n",
    "x = torch.randn(batch_size, D)\n",
    "y = torch.randint(low=0,high=Dout,size=(batch_size,))\n",
    "\n",
    "mdl = nn.Linear(D, Dout)\n",
    "logits = mdl(x)\n",
    "print(f'y.size() = {y.size()}')\n",
    "# removes the 1th dimension with a max, which is the classification layer\n",
    "# which means it returns the most likely label. Also, note you need to choose .indices since you want to return the\n",
    "# position of where the most likely label is (not it's raw logit value)\n",
    "pred = logits.max(1).indices\n",
    "print(pred)\n",
    "\n",
    "print('--- preds vs truth ---')\n",
    "print(f'predictions = {pred}')\n",
    "print(f'y = {y}')\n",
    "\n",
    "acc = (pred == y).sum().item() / pred.size(0)\n",
    "print(acc)\n",
    "print(calc_accuracy(mdl, x, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/runtimeerror-element-0-of-variables-does-not-require-grad-and-does-not-have-a-grad-fn/11074/20\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "x = torch.randn(1)\n",
    "mdl = nn.Linear(1, 1)\n",
    "\n",
    "y = mdl(x)\n",
    "print(mdl.weight)\n",
    "\n",
    "print(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-get-the-module-names-of-nn-sequential/39682\n",
    "# looping through modules but get the one with a specific name\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "params = OrderedDict([\n",
    "    ('fc0', nn.Linear(in_features=4,out_features=4)),\n",
    "    ('ReLU0', nn.ReLU()),\n",
    "    ('fc1L:final', nn.Linear(in_features=4,out_features=1))\n",
    "])\n",
    "mdl = nn.Sequential(params)\n",
    "\n",
    "# throws error\n",
    "# mdl['fc0']\n",
    "\n",
    "for m in mdl.children():\n",
    "    print(m)\n",
    "\n",
    "print()\n",
    "\n",
    "for m in mdl.modules():\n",
    "    print(m)\n",
    "\n",
    "print()\n",
    "\n",
    "for name, m in mdl.named_modules():\n",
    "    print(name)\n",
    "    print(m)\n",
    "\n",
    "print()\n",
    "\n",
    "for name, m in mdl.named_children():\n",
    "    print(name)\n",
    "    print(m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply mdl to x until the final layer, then return the embeding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "Din, Dout = 1, 1\n",
    "H = 10\n",
    "\n",
    "modules = OrderedDict([\n",
    "    ('fc0', nn.Linear(in_features=Din,out_features=H)),\n",
    "    ('ReLU0', nn.ReLU()),\n",
    "\n",
    "    ('fc1', nn.Linear(in_features=H,out_features=H)),\n",
    "    ('ReLU1', nn.ReLU()),\n",
    "\n",
    "    ('fc2', nn.Linear(in_features=H,out_features=H)),\n",
    "    ('ReLU2', nn.ReLU()),\n",
    "\n",
    "    ('fc3', nn.Linear(in_features=H,out_features=H)),\n",
    "    ('ReLU3', nn.ReLU()),\n",
    "\n",
    "    ('fc4L:final', nn.Linear(in_features=H,out_features=Dout))\n",
    "])\n",
    "\n",
    "mdl = nn.Sequential(modules)\n",
    "\n",
    "out = x\n",
    "for name, m in self.base_model.named_children():\n",
    "    if 'final' in name:\n",
    "        # return out\n",
    "        break\n",
    "    out = m(out)\n",
    "\n",
    "print(out.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n"
     ]
    }
   ],
   "source": [
    "# initializing a constant weight net\n",
    "# https://discuss.pytorch.org/t/how-to-add-appropriate-noise-to-a-neural-network-with-constant-weights-so-that-back-propagation-training-works/93411\n",
    "\n",
    "# import torch\n",
    "\n",
    "# [layer.reset_parameters() for layer in base_model.children() if hasattr(layer, 'reset_parameters')]\n",
    "\n",
    "# model = nn.Linear(1, 1)\n",
    "# model_copy = copy.deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}