"""
https://chatgpt.com/g/g-cH94JC5NP-dspy-guide-v2024-2-7/c/66e7ba95-399c-8001-91a4-a1a26b8fbed5
"""
import dspy
from dspy.datasets import HotPotQA
from dspy.evaluate.evaluate import Evaluate

# Set up the language model (LM) using OpenAI GPT-3.5-turbo
turbo = dspy.OpenAI(model='gpt-3.5-turbo')
dspy.settings.configure(lm=turbo)  # No retriever (RM) module is used.

# Load the training dataset
dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)

# Process the dataset to work with DSPy
trainset = [x.with_inputs('question') for x in dataset.train]
devset = [x.with_inputs('question') for x in dataset.dev]

# 1. Define the signature for the synthetic QA generation
class SyntheticQAGeneration(dspy.Signature):
    """Generate synthetic QA pairs from a given context."""
    context = dspy.InputField(desc="Context for generating synthetic questions and answers")
    question = dspy.OutputField(desc="Generated question")
    answer = dspy.OutputField(desc="Generated answer")

# 2. ICL Module that takes a synthetic question and generates an answer
class ICLAnswerModule(dspy.Signature):
    """Use ICL to generate answers given a question."""
    context = dspy.InputField(desc="Context for ICL")
    question = dspy.InputField(desc="Synthetic question generated")
    answer = dspy.OutputField(desc="Answer generated by ICL")

# 3. DSPy module for the overall pipeline
class SyntheticDataPipeline(dspy.Module):
    def __init__(self):
        super().__init__()

        # Phase 1: Generate synthetic QA pairs from context
        self.generate_qa = dspy.ChainOfThought(SyntheticQAGeneration)
        
        # Phase 2: ICL with the generated question to answer it
        self.answer_icl = dspy.ChainOfThought(ICLAnswerModule)

    def forward(self, context):
        # Step 1: Generate the QA from context
        qa_result = self.generate_qa(context=context)
        generated_question = qa_result.question
        generated_answer = qa_result.answer
        
        # Step 2: Use ICL to answer the generated question
        icl_result = self.answer_icl(context=context, question=generated_question)
        icl_answer = icl_result.answer

        return dspy.Prediction(synthetic_question=generated_question, synthetic_answer=generated_answer, icl_answer=icl_answer)

# 4. Teleprompter setup with BootstrapFewShotWithRandomSearch
from dspy.teleprompt import BootstrapFewShotWithRandomSearch

# Validation function: check if predicted answer matches expected answer (exact match metric)
def validate_answer(example, pred, trace=None):
    # Compare the generated answer with the expected answer using exact match
    return dspy.evaluate.answer_exact_match(example, pred)

# Teleprompter for optimization using random search
teleprompter = BootstrapFewShotWithRandomSearch(metric=validate_answer)

# Compile the synthetic data generation pipeline using the teleprompter
compiled_pipeline = teleprompter.compile(SyntheticDataPipeline(), trainset=trainset)

# 5. Set up the evaluation function for the model
evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=False, display_table=5)

# Ask a sample question to test the pipeline
sample_context = "David Gregory, a famous figure, inherited a large estate in 1743."
test_question = "What estate did David Gregory inherit?"

# Run the compiled pipeline with the sample context
pred = compiled_pipeline(sample_context)

# Print the results: synthetic question, generated answer, and ICL-generated answer
print(f"Context: {sample_context}")
print(f"Synthetic Question: {pred.synthetic_question}")
print(f"Synthetic Answer: {pred.synthetic_answer}")
print(f"ICL Answer: {pred.icl_answer}")

# 6. Evaluate the pipeline on the dev set using the exact match metric
metric = dspy.evaluate.answer_exact_match
evaluation_result = evaluate_on_hotpotqa(compiled_pipeline, metric=metric)

# Print the evaluation results
print("Evaluation result:", evaluation_result)

# Optionally, print out a few final examples from the dev set to analyze
for example in devset[:5]:
    pred = compiled_pipeline(example['context'])
    print(f"Context: {example['context']}")
    print(f"Synthetic Question: {pred.synthetic_question}")
    print(f"ICL Answer: {pred.icl_answer}")
